{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from segmenter_model_zoo.zoo import SegModel\n",
    "from aicsimageio import AICSImage\n",
    "from itkwidgets import view\n",
    "import numpy as np\n",
    "from aicsmlsegment.utils import background_sub, simple_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1: define a basic model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = SegModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA_mask_production\n",
      "DNA_seed_production\n",
      "CellMask_edge_production\n",
      "CAAX_production\n",
      "LMNB1_all_production\n",
      "LMNB1_fill_production\n",
      "LMNB1_core_production\n",
      "LF_DNA_mask\n",
      "LF_DNA_mask_two_camera\n",
      "LF_mem_edge\n",
      "LF_mem_edge_two_camera\n",
      "H2B_coarse\n"
     ]
    }
   ],
   "source": [
    "# you can check all avaialable models:\n",
    "my_model.list_all_trained_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2: load one pre-trained model\n",
    "\n",
    "Suppose you want to load the \"DNA_mask_production\". You can do `my_model.load_train('DNA_mask_production')`. This will automatically download the pre-trained model from cloud storage and save a local copy at \"./\". You can also specify where to save the local copy by, for example, `my_model.load_train('DNA_mask_production', {\"local_path\":\"./all_models/\"})`. If you already have downloaded the model before and saved it at \"./all_models/\", there won't be any download and the local model will be directly loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model DNA_mask_production is successfully loaded\n"
     ]
    }
   ],
   "source": [
    "my_model.load_train('DNA_mask_production', {\"local_path\":\"./\"})\n",
    "my_model.to_gpu('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3: apply the model on one image\n",
    "\n",
    "There are two different ways to apply the model: applying on a numpy array or just providing a filepath and which channel to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtracted background\n"
     ]
    }
   ],
   "source": [
    "# read one image as numpy array, and apply the model on it\n",
    "reader = AICSImage(\"C:/projects/demo/data/3500000875_100X_20170508_12-Scene-3-P37-E06.ome.tiff\")\n",
    "dna_img = reader.get_image_data(\"CZYX\", C=[-2], S=0, T=0)\n",
    "dna_mask = my_model.apply_on_single_zstack(dna_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output is not binary by default. The value is between 0 and 1, indicating the probability of \n",
    "# being object/ Bindary results can be obtained by a cutoff value\n",
    "dna_mask_bw = dna_mask>0.7\n",
    "dna_mask_bw = dna_mask_bw.astype(np.uint8)\n",
    "dna_mask_bw[dna_mask_bw>0]=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb82ebaa16b451793c295729608ffd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[], gradient_opacity=0.22, point_sets=[], rendered_image=<itk.itkImagePython.itkImageUC3; pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(dna_mask_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtracted background\n"
     ]
    }
   ],
   "source": [
    "# or we can just provide the filename and which channel to use. \n",
    "# We can also pass in the cutoff so the returned value is already binary\n",
    "fn = \"C:/projects/demo/data/3500000875_100X_20170508_12-Scene-3-P37-E06.ome.tiff\"\n",
    "dna_mask_bw = my_model.apply_on_single_zstack(filename=fn, inputCh=-2, cutoff=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a10dd8156d48d483f5043c0ecec63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[], gradient_opacity=0.22, point_sets=[], rendered_image=<itk.itkImagePython.itkImageUC3; pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(dna_mask_bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "\n",
    "The model was developed for working on images from the Allen Cell Data Collection. When applying on your own data, it may or may not work well. If not good, what to do? \n",
    "\n",
    "First, our data was built for 100x ZEISS spinning disk images. The physical size of each voxel is 0.108 um x 0.108 um x 0.29 um (XYZ). If you image is of different magnification, try resize your image before applying the model.\n",
    "\n",
    "Second, you can try different image normalization methods. You can check out which normalization method each model is using (e.g. [here](https://github.com/AllenCell/segmenter_model_zoo/blob/main/segmenter_model_zoo/zoo.py#L43) ), check the exact implementation of each normalization method [here](https://github.com/AllenInstitute/aics-ml-segmentation/blob/master/aicsmlsegment/utils.py#L98). Then, you can pick one image from our data and apply the normalization method the model is using and see how it looks. Then, you may adjust the normalization method to be applied on your data so that the normalized image is comparable to the normalization results on our data, in terms of contrast, brightness, etc.. Finally, you can load your image, do your new normalization on image, apply the model like this `my_model.apply_on_single_zstack(dna_img, already_normalized, already_normalized=True)` This is bypass any normalizaiton the model does by default.\n",
    "\n",
    "Finally, it is possible that the models won't work off-the-shelf. That's okay. The essential philosophy behind the iterative deep learning workflow is to start with some preliminary results and gradually improve the performance. So, try the two adjustments above about magnification and normalization in order to make the results as good as possible. Then, if you can find just a few cells where the segmentation is acceptable, then you can use the curation tool in our Segmenter (see [here](https://github.com/AllenInstitute/aics-ml-segmentation/blob/master/docs/bb2.md)) to collect a few good examples to finetune the model on your data. Then, when applying the new model on your data, the results may be better. You may need one more iteration of curation + training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
